{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell2idx = {\n",
    "    'A549': 0,\n",
    "    'GM12878': 1,\n",
    "    'HCT116': 2,\n",
    "    'HEPG2': 3,\n",
    "    'K562': 4,\n",
    "    'MCF7': 5,\n",
    "    'Negative': 6,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base2int = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "\n",
    "def sequence2int(sequence, mapping=base2int):\n",
    "    return [mapping.get(base, 999) for base in sequence]\n",
    "\n",
    "def sequence2onehot(sequence, mapping=base2int):\n",
    "    return tf.one_hot(sequence2int(sequence, mapping), depth=4)\n",
    "\n",
    "def load_fasta(fasta, cell2idx):\n",
    "    with open(fasta) as f:\n",
    "        for line in f:\n",
    "            assert line[0] == '>'\n",
    "            header, sequence = line.strip(), f.readline().strip()\n",
    "            name, *_ = header[1:].split(':')\n",
    "            \n",
    "            if name not in cell2idx:\n",
    "                continue\n",
    "            \n",
    "            yield tf.cast(sequence2onehot(sequence), tf.float32), cell2idx[name]\n",
    "\n",
    "def load_dataset(fasta, cell2idx, cache=False, shuffle=False):\n",
    "    #positive_label = tf.cast(positive_label, tf.string)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_generator(lambda: load_fasta(fasta, cell2idx), output_types=(tf.float32, tf.int8))\n",
    "    \n",
    "    #dataset = dataset.filter(lambda x, y: x in cell2idx)\n",
    "    #dataset = dataset.map(lambda x, y: (x, cell2idx[y.numpy()]))\n",
    "        \n",
    "    #dataset = dataset.map(lambda x, y: (x, tf.cast(y == positive_label, tf.int8)))\n",
    "    \n",
    "    if cache:\n",
    "        dataset = dataset.cache()\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(1_000_000)\n",
    "    dataset = dataset.batch(256)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('../data.csv/processed/train/train.fasta', cell2idx, cache=True, shuffle=True)\n",
    "print(dataset.element_spec)\n",
    "for x in dataset.take(1):\n",
    "    print(x)\n",
    "    \n",
    "dataset_test = load_dataset('../data.csv/processed/test/test.fasta', cell2idx, cache=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.config.multi-class.json') as f:\n",
    "    model_config = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Model().from_config(model_config)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create callbacks\n",
    "log_dir = 'logs.multi-class/' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "print(log_dir)\n",
    "\n",
    "callbacks = [\n",
    "    #tf.keras.callbacks.EarlyStopping(patience=15),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create metrics\n",
    "# metrics = {\n",
    "#     'auROC':  tf.keras.metrics.AUC(curve='ROC', multi_label=True),\n",
    "#     'accuracy': tf.keras.metrics.Accuracy(),\n",
    "#     'precision': tf.keras.metrics.Precision(),\n",
    "#     'recall': tf.keras.metrics.Recall(),\n",
    "# }\n",
    "\n",
    "metrics = [\n",
    "    tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "]\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "model.fit(dataset, validation_data=dataset_test, epochs=EPOCHS, callbacks=callbacks)\n",
    "model.save(f'{log_dir}/model.multitask.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "150bef772f693d9716bc82fba65767b2dbc77b933509c2459cc29d1b0e410b48"
  },
  "kernelspec": {
   "display_name": "Python [conda env:rbpnet-2.0]",
   "language": "python",
   "name": "conda-env-rbpnet-2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
